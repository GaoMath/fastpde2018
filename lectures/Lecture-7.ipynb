{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 7. Solvers for large-scale sparse systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Previous lecture\n",
    "- PDEs discretization\n",
    "- Sparse matrices\n",
    "- Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Todays lecture\n",
    "- Direct solvers\n",
    "- Iterative solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Typical problems we need to solve\n",
    "\n",
    "1. Solving linear systems $Ax = f$\n",
    "2. Solving eigenvalue problem $A x_i = \\lambda x_i$\n",
    "3. Computing matrix functions, i.e. $y = e^{At} y_0$\n",
    "\n",
    "To solve 2 and 3 we need to solve auxiliary linear systems. \n",
    "\n",
    "Types of solvers\n",
    "- iterative: matrix-by-vector product is **easy**, but the matrix is typically **ill-conditioned**, thus iterative methods will converge slowly, and **preconditioners** are needed\n",
    "- direct: no problem with ill-conditioning, but complexity is not optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fast direct solvers\n",
    "\n",
    "One of the research directions for solving sparse linear systems\n",
    "\n",
    "$$\n",
    "A x = f\n",
    "$$\n",
    "\n",
    "with a given **sparse matrix** $A$ are so-called **direct solvers** which try to factorize the matrix $A$.\n",
    "\n",
    "The simplest decomposition is the **sparse LU** factorization of the form\n",
    "\n",
    "$$A = LU,$$\n",
    "\n",
    "where $L$ is **sparse lower triangular**, and $U$ is **sparse upper triangular**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparse Gaussian elimination and graphs\n",
    "\n",
    "- The crucial concept to analyze the efficiency of sparse matrix factorization is the **sparse matrix graph**.\n",
    "\n",
    "- The graph of the sparse matrix has vertices $i$, and the edge exists if $A_{ij} \\ne 0$.\n",
    "\n",
    "- The pattern of the $L$ factor can be inferred from the **symbolic** operations in the sparse matrix graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graph of the sparse matrix\n",
    "\n",
    "For simplicity, consider **Cholesky factorization** for a **symmetric positive-definite matrix** $A$:\n",
    "\n",
    "$$A = LL^{\\top}.$$\n",
    "\n",
    "The positions of non-zero elements can be inferred from the code\n",
    "\n",
    "```\n",
    "\n",
    "for j from 1 to N:\n",
    "\n",
    "   Add edges between j's higher-order neighbors\n",
    "   \n",
    "```\n",
    "\n",
    "<img src='pic/screen.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Permutation selection\n",
    "\n",
    "- The fill-in of a matrix are those entries which change from an initial zero to a nonzero value during the execution of an algorithm.\n",
    "\n",
    "- The fill-in is different for different permutations. So, before factorization we need to find reordering which produces the smallest fill-in.\n",
    "\n",
    "- For one order you get sparse factorization, for another - dense factors.\n",
    "\n",
    "In fact, for a Cholesky factorization you compute\n",
    "\n",
    "$$A = P L L^{\\top} P^{\\top},$$\n",
    "\n",
    "where $P$ is a **permutation matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2D model problem\n",
    "\n",
    "- 2D model problem: Poisson equation on $n \\times n$ finite difference grid\n",
    "- Total number of unknowns $n^2 = N$\n",
    "- Theoretical results from the fill-in:\n",
    "  - Natural (no) permutation: $\\mathcal{O}(N^{3/2})$\n",
    "  - Random permutation: expected value is $\\mathcal{O}(N \\log N)$\n",
    "  - Nested dissection permutation: $\\mathcal{O}(N)$.\n",
    "  \n",
    "  By **fill-in** I mean the number of non-zeros in the $L$ factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0xa17a3a7b8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "from scipy.sparse import csc_matrix, csr_matrix, coo_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 20\n",
    "ex = np.ones(n);\n",
    "lp1 = sp.sparse.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
    "e = sp.sparse.eye(n)\n",
    "A = sp.sparse.kron(lp1, e) + sp.sparse.kron(e, lp1)\n",
    "A = csc_matrix(A)\n",
    "T = scipy.sparse.linalg.splu(A)\n",
    "plt.spy(T.L, marker='.', color='k', markersize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested dissection ordering\n",
    "\n",
    " A **separator** in a graph $G$ is a set $S$ of vertices whose removal leaves at\n",
    "least two connected components\n",
    "- A nested dissection ordering for an $N$-vertex graph $G$ numbers its\n",
    "vertices from $1$ to $N$ as follows:\n",
    "    - Find a separator $S$, whose removal leaves connected components\n",
    "$T_1$, $T_2$, $\\ldots$, $T_k$\n",
    "    - Number the vertices of $S$ from $N − |S| + 1$ to $N$\n",
    "    - Recursively, number the vertices of each component: $T_1$ from $1$ to\n",
    "$|T_1|$, $T_2$ from $|T_1| + 1$ to $|T_1| + |T_2|$, etc\n",
    "- If a component is small enough, number it arbitrarily\n",
    "\n",
    "It all boils down to finding good separators! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested dissection is \"approximately optimal\"\n",
    "\n",
    "- From theory, nested dissection gives you optimal complexity\n",
    "\n",
    "- Again, there are other methods that win for medium-sized problems\n",
    "\n",
    "- They are based on **heuristic** matrix reordering techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Banded reordering\n",
    "\n",
    "- Make the matrix more \"banded\" (Reverse Cuthill-McKee, Sloan, etc.)\n",
    "\n",
    "- The idea is to try to keep entries closer to the diagonal \n",
    "\n",
    "- It works well for matrices coming from \"quasi-one dimensional\" PDEs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Minimal degree orderings\n",
    "\n",
    "-  The idea is to eliminate rows and/or columns with fewer non-zeros, update fill-in and repeat\n",
    "\n",
    "- Efficient implementation is an issue (adding/removing elements)\n",
    "\n",
    "- Current champion is \"approximate minimal degree\" by [Amestoy, Davis, Duff](https://pdfs.semanticscholar.org/606a/5dce82d9953aa18b732691b427231b87be90.pdf)\n",
    "\n",
    "- It is **suboptimal** even for 2D problems\n",
    "\n",
    "- In practice, it often wins for medium-sized problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested dissection\n",
    "\n",
    "- Find a separator, number it last, proceed recursively\n",
    "- Optimal in theory\n",
    "- In practice, beats others for very large problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solving sparse matrices, coming from PDEs\n",
    "\n",
    "<img src='pic/complexity2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Separators in practice\n",
    "\n",
    "Computing separators is not a **trivial task**.\n",
    "\n",
    "Graph partitioning heuristics have been an active research area for many years, often motivated by partitioning for parallel computation.\n",
    "\n",
    "Existing approaches:\n",
    "\n",
    "- Spectral partitioning (uses eigenvectors of Laplacian matrix of graph)\n",
    "- Geometric partitioning (for meshes with specified vertex coordinates)\n",
    "- Iterative-swapping (Kernighan-Lin, Fiduccia-Matheysses)\n",
    "- Breadth-first search \n",
    "\n",
    "Many popular modern codes (e.g. Metis, Chaco) use multilevel iterative swapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iterative swapping\n",
    "\n",
    "The \"cost\" of the separator is defined in a very natural way as the sum over edges:\n",
    "\n",
    "$$T(A, B) = \\sum_{e = (v_a, v_b), v_a \\in  A, v_b \\in B} \\text{weight}(e).$$\n",
    "\n",
    "Given some initial partion, test some subsets $X$ and $Y$ of the same size, and if swapping decreases the cost function - swap them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spectral bisection\n",
    "\n",
    "The idea of spectral bisection goes back to Fiedler.\n",
    "\n",
    "We introduce the **graph Laplacian** of the matrix, which is defined as as symmetric matrix\n",
    "\n",
    "that\n",
    "\n",
    "$$L_{ii} = \\text{degree of node } i$$\n",
    "\n",
    "$$L_{ij} = \\begin{cases} -1, & i \\ne j\\\\ 0 & \\text{otherwise}\\end{cases}$$\n",
    "\n",
    "- Rows of $L$ sum to zero, thus there is an eigenvalue $1$\n",
    "- Eigenvalues are non-negative.\n",
    "- The number of connected components of a graph is the number of **zero eigenvalues**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to use sparse direct solvers?\n",
    "\n",
    "- They work well for 1D/2D problems and \"not so large\" 3D problems. \n",
    "\n",
    "- The problem with memory becomes very harsh for 3D problems, thus other methods are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Structure of sparse matrices, coming from PDEs\n",
    "\n",
    "For a general sparse matrix, fast direct method is typically the method of choice.\n",
    "\n",
    "A sparse matrix coming from a PDE, the rows/columns can be associated with **points** (elements) in a $d$-dimensional space, just like for the $\\mathcal{H}$-matrix case.\n",
    "\n",
    "This is an additional structure that can be used in many ways, for example by approximating factors using $\\mathcal{H}$-matrix case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fast direct solvers and $\\mathcal{H}$-matrices\n",
    "\n",
    "- Inverse of a sparse matrix is typically not sparse\n",
    "- But for PDEs it has lowrank blocks ($\\mathcal{H}, \\mathcal{H}^2$-matrix). \n",
    "- This information can be utilized to build efficient solver. \n",
    "\n",
    "Details on the blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1. -2.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1. -2.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -2.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -2.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1. -2.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1. -2.]]\n",
      "[[-0.875 -0.75  -0.625 -0.5   -0.375 -0.25  -0.125]\n",
      " [-0.75  -1.5   -1.25  -1.    -0.75  -0.5   -0.25 ]\n",
      " [-0.625 -1.25  -1.875 -1.5   -1.125 -0.75  -0.375]\n",
      " [-0.5   -1.    -1.5   -2.    -1.5   -1.    -0.5  ]\n",
      " [-0.375 -0.75  -1.125 -1.5   -1.875 -1.25  -0.625]\n",
      " [-0.25  -0.5   -0.75  -1.    -1.25  -1.5   -0.75 ]\n",
      " [-0.125 -0.25  -0.375 -0.5   -0.625 -0.75  -0.875]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as spsp\n",
    "n = 7\n",
    "ex = np.ones(n);\n",
    "a = spsp.spdiags(np.vstack((ex,  -2*ex, ex)), [-1, 0, 1], n, n, 'csr'); \n",
    "a = a.todense()\n",
    "b = np.array(np.linalg.inv(a))\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iterative methods\n",
    "\n",
    "- If we want to achieve $\\mathcal{O}(N)$ complexity, then direct solvers are not appropriate\n",
    "- If we want to solve partial eigenproblem, the full eigendecomposition is too costly\n",
    "\n",
    "- For both problems we will use iterative, Krylov subspace solvers\n",
    "- They treat the matrix as a **black-box** linear operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix as a black box\n",
    "\n",
    "We have now an absolutely different view on a matrix: \n",
    "- matrix is now a **linear operator**, that acts on a vector  \n",
    "- this action can be computed in $\\mathcal{O}(N)$ operations\n",
    "\n",
    "**This is the only information** we know about the matrix: \n",
    "\n",
    "the <font color='red'> matrix-by-vector product (matvec) </font>\n",
    "\n",
    "**Q:** can we solve linear systems using only matvecs?\n",
    "\n",
    "**A:** of course, we can multiply by the colums of the identity matrix, and \n",
    "\n",
    "recover the full matrix, but it is not what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Krylov subspace methods\n",
    "\n",
    "-  Krylov subspace of the matrix $A$ given vector $f$ is defined as \n",
    "$$\n",
    "   K_m(A, f) = \\mathrm{Span}(f, Af, A^2 f, \\ldots, A^{m-1}f )\n",
    "$$\n",
    "- Krylov methods (known from NLA course):\n",
    "    - CG works for SPD matrices, minimizes energy functional over Krylov subspace\n",
    "    - Minres works for symmetric matrices, minimizes residual\n",
    "    - GMRES works for general matrices, also minimizes residual but does not have recurrent formulas $\\to$ restarting  \n",
    "    - BiCGstab works for general matrices, does not minimize functional but has short recurrent formulas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \"Nonlinear GMRES\" or Anderson acceleration\n",
    "\n",
    "Use the GMRES-like idea to speed up a given fixed-point iteration\n",
    "\n",
    "$$x_{k+1} = \\Phi(x_k).$$\n",
    "\n",
    "Idea: **use history** for the update, \n",
    "\n",
    "$$x_{k+1} = \\Phi(x_k) + \\sum_{s=1}^m \\alpha_s (x_{k - s} - \\Phi(x_{k - s})), $$\n",
    "\n",
    "and the parameters $\\alpha_s$ are selected to minimize the norm of the residual.\n",
    "\n",
    "- This was actually older than the GMRES\n",
    "- It is known as an Direct Inversion in Iterated Subspaces in Quantum Chemistry, or **Anderson Acceleration**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Battling the condition number\n",
    "\n",
    "- The condition number problem is **un-avoidable** if only matvec is used\n",
    "- Thus we need an **army of preconditioners** to solve it\n",
    "- There are several **general purpose** preconditioners that we can use\n",
    "- But often for a particular problem a special design is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preconditioner: general concept\n",
    "\n",
    "The general concept of the preconditioner is simple:\n",
    "\n",
    "Given a linear system \n",
    "\n",
    "$$A x = f,$$\n",
    "\n",
    "we want to find the matrix $P_R$ (or $P_L$) such that \n",
    "\n",
    "1. Condition number of $AP_R^{-1}$ (right preconditioner) or $P^{-1}_LA$ (left preconditioner) or $P^{-1}_L A P_R^{-1}$ is better than for $A$\n",
    "2. We can easily solve $P_Ly = g$ or $P_Ry = g$ for any $g$ (otherwise we could choose e.g. $P_L = A$)\n",
    "\n",
    "Then we solve for (right preconditioner)\n",
    "\n",
    "$$ AP_R^{-1} y = f \\quad \\Rightarrow \\quad P_R x = y$$ \n",
    "\n",
    "or  (left preconditioner)\n",
    "\n",
    "$$ P_L^{-1} A x = P_L^{-1}f,$$\n",
    "\n",
    "or even both\n",
    "\n",
    "$$ P_L^{-1} A P_R^{-1} y = P_L^{-1}f \\quad \\Rightarrow \\quad P_R x = y.$$ \n",
    "\n",
    "- The best choice is of course $P = A,$ but this does not make life easier\n",
    "- One of the ideas is to use other iterative methods (beside Krylov) as preconditioners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incomplete LU\n",
    "\n",
    "\n",
    "Suppose you want to eliminate a variable $x_1$, and the equations have the form\n",
    "\n",
    "$$5 x_1 + x_4 + x_{10} = 1, \\quad 3 x_1 + x_4 + x_8 = 0, \\ldots,$$\n",
    "\n",
    "and in all other equations $x_1$ are not present. \n",
    "\n",
    "After the elimination, only $x_{10}$ will enter additionally to the second equation (new fill-in).\n",
    "\n",
    "$$x_4 + x_8 + 3(1 - x_4 - x_{10})/5 = 0$$\n",
    "\n",
    "In the Incomplete $LU$ case (actually, ILU(0)) we just throw away the **new fill-in**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incomplete-LU: formal definition\n",
    "\n",
    "We run the usual LU-decomposition cycle, but avoid inserting non-zeros **other** than the initial non-zero pattern. \n",
    "\n",
    "```python\n",
    "\n",
    "    L = np.zeros((n, n))\n",
    "    \n",
    "    U = np.zeros((n, n))\n",
    "    \n",
    "    for k in range(n): #Eliminate one row\n",
    "        \n",
    "        L[k, k] = 1\n",
    "        \n",
    "        for i in range(k+1, n):\n",
    "            \n",
    "            L[i, k] = a[i, k] / a[k, k]\n",
    "            \n",
    "            for j in range(k+1, n):\n",
    "                \n",
    "                a[i, j] = a[i, j] - L[i, k] * a[k, j]  #New fill-ins appear here\n",
    "                \n",
    "        for j in range(k, n):\n",
    "            \n",
    "            U[k, j] = a[k, j]\n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ILU(k)\n",
    "\n",
    "- Yousef Saad (who is the author of GMRES) also had a seminal paper on the **Incomplete LU** decomposition\n",
    "\n",
    "- A good book on the topic is [Iterative methods for sparse linear systems](https://www-users.cs.umn.edu/~saad/IterMethBook_2ndEd.pdf) by Saad, Yousef (1996)\n",
    "\n",
    "- And he proposed **ILU(k)** method, which has a nice interpretation in terms of graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ILU(k): idea\n",
    "\n",
    "- The idea of ILU(k) is very instructive and is based on the connection between sparse matrices and graphs\n",
    "\n",
    "- Suppose you have an $n \\times n$ matrix $A$ and a corresponding adjacency graph\n",
    "\n",
    "- Then we eliminate one variable (vertex) and get a smaller system of size $(n-1) \\times (n-1)$\n",
    "\n",
    "- New edges (=fill-in) appears between high-order neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LU & graphs\n",
    "\n",
    "- The **ILU(k)** idea is to leave only the elements in $L$ and $U$ that are $k$-order neighbours in the original graph.\n",
    "\n",
    "- The ILU(2) is very efficient, but for some reason completely abandoned (i.e. there is no implementation in MATLAB and SciPy).\n",
    "\n",
    "There is an original [Sparsekit software](https://people.sc.fsu.edu/~jburkardt/f_src/sparsekit/sparsekit.html) by Saad, which works quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ILU Thresholded (ILUT)\n",
    "A much more popular approach uses the so-called **thresholded LU**.\n",
    "\n",
    "You do the standard Gaussian elimination with fill-ins, but either:\n",
    "\n",
    "- Throw away elements that are smaller than threshold, and/or control the amount of non-zeros you are allowed to store.\n",
    "\n",
    "- The smaller is the threshold, the better is the preconditioner, but more memory it takes.\n",
    "\n",
    "It is denoted ILUT($\\tau$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Symmetric positive definite case\n",
    "\n",
    "In the SPD case, instead of incomplete LU you should use Incomplete Cholesky, which is twice faster and consumes twice less memory.\n",
    "\n",
    "- **ILUT** is implemented in [SciPy](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.linalg.spilu.html#scipy.sparse.linalg.spilu)\n",
    "- **Ichol** is implemented in [Scikit-sparse package](https://pythonhosted.org/scikits.sparse/cholmod.html) \n",
    "- You can try (nothing quite fancy, but it works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Second-order LU preconditioners\n",
    "\n",
    "- There is a more efficient **second-order** LU factorization [proposed by I. Kaporin](http://www.researchgate.net/profile/I_Kaporin/publication/242940993_High_quality_preconditioning_of_a_general_symmetric_positive_definite_matrix_based_on_its_UTU__UTR__RTU-decomposition/links/53f72ad90cf2888a74976f54.pdf)\n",
    "\n",
    "- It is but much less popular due to the limit of open-source implementations\n",
    "\n",
    "- The idea is to approximate the matrix in the form\n",
    "\n",
    "$$A \\approx U_2 U^{\\top}_2 + U^{\\top}_2 R_2 + R^{\\top}_2 U_2,$$\n",
    "\n",
    "where $U_1$ and $U_2$ are low-triangular and sparse, whereare $R_2$ is small with respect to the drop tolerance parameter\n",
    "\n",
    "- This is just the expansion of the $UU^{\\top}$ with respect to the perturbation of $U$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Summary\n",
    "- Fast direct solvers are often the method of choice for small-sized problems.\n",
    "- Iterative methods\n",
    "- Preconditioning"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
